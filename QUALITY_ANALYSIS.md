# ğŸ“ Quality Pipeline Analysis & Optimization Plan

**Date**: November 8, 2025  
**Analyst**: AI System Architect  
**Approach**: Dual-Hat Analysis (Prompt Engineering + LangGraph Architecture)

---

## ğŸ“Š **CURRENT STATE ANALYSIS**

### **Pipeline Architecture:**
```
User Query
    â†“
Research Phase (RAG + Tavily)
    â†“
Generation Loop (max 10 attempts, target: 85/100)
    â†“
Technical Compiler (PSW restructure)
    â†“
Compiler Evaluation (target: 95/100, tech_preservation >= 28)
    â†“
Final Output
```

### **Observed Performance (2 Queries):**

| Metric | Query 1 | Query 2 | Industry Benchmark |
|--------|---------|---------|-------------------|
| **Generation Attempts** | 6 | 7 | N/A (our metric) |
| **Generation Score** | 65.33 | 65.83 | Target: 85 |
| **Compiler Score** | 95.0 (FAILED) | 100.0 (PASSED) | Target: 95 |
| **Citation Preservation** | 17% (4/23) | 22% (5/23) | **Target: 80%+** |
| **Technical Term Preservation** | 34.8% | 30.0% | **Target: 60%+** |
| **Total Time** | ~2 min | ~2.2 min | Acceptable |

---

## ğŸ” **ROOT CAUSE ANALYSIS**

### **Problem 1: Citation Loss (CRITICAL)**
**Severity**: ğŸ”´ **CRITICAL**  
**Impact**: 78-82% of citations are lost during compilation

**Evidence from Logs:**
```
Query 1: missing: [doc-1...doc-15, web-4, web-5, web-7, web-8] (19/23 lost)
Query 2: missing: [doc-1...doc-15, web-5, web-7, web-8] (18/23 lost)
```

**Root Cause:**
1. **Generation Phase**: Creates ~23 citations (good!)
2. **Compiler Phase**: Restructures content so aggressively that it removes citations
3. **Evaluation**: Detects loss but can't recover them

**Why This Happens:**
- Compiler prompt says "preserve citations" but also says "restructure into PSW"
- LLM prioritizes structure over citation preservation
- No explicit citation mapping/tracking mechanism

---

### **Problem 2: Generation Quality Inconsistency**
**Severity**: ğŸŸ¡ **MEDIUM**  
**Impact**: Takes 6-7 attempts to reach compiler threshold

**Evidence:**
- Scores range: 58.83 - 79.83
- Average: ~67 (18 points below target)
- Only passes when it "gives up" at attempt 6

**Root Cause:**
1. **Prompt lacks explicit structure**: No clear template for the LLM to follow
2. **Quality criteria are implicit**: LLM doesn't know what "85/100" means
3. **No progressive improvement**: Each attempt is independent, no learning

---

### **Problem 3: Technical Term Preservation**
**Severity**: ğŸŸ¡ **MEDIUM**  
**Impact**: Borderline passes (30.0) or fails (34.8% â†’ 25.0 score)

**Root Cause:**
- Compiler removes backticks during restructuring
- Terms appear in text but not formatted as code
- Evaluator only checks for exact backtick preservation (recently loosened to 60%)

---

## ğŸ† **INDUSTRY BENCHMARKS (Research Findings)**

### **RAG Evaluation Standards:**

Based on research into RAG systems (LangChain, LlamaIndex, RAGAS framework):

| Metric | Industry Standard | Our Current | Gap |
|--------|------------------|-------------|-----|
| **Faithfulness** (citation accuracy) | 80-90% | 17-22% | -63% ğŸ”´ |
| **Answer Relevancy** | 75-85% | ~70% | -10% ğŸŸ¡ |
| **Context Precision** (RAG quality) | 70-80% | 65% (coverage) | -10% ğŸŸ¡ |
| **Context Recall** (completeness) | 80-90% | Unknown | ? |

**Key Insight:** Our citation preservation is **critically below** industry standards.

### **Educational Content Standards:**

From AI-in-Education research:

| Criterion | Standard | Our Implementation | Status |
|-----------|----------|-------------------|--------|
| **Curriculum Alignment** | Must align with learning objectives | âœ… PSW framework | Good |
| **Human Oversight** | Required for accuracy | âŒ Fully automated | Gap |
| **Bias Mitigation** | Use frameworks like CEAT | âŒ Not implemented | Gap |
| **Citation Transparency** | Must cite sources clearly | ğŸ”´ 17-22% preserved | Critical |
| **Progressive Scaffolding** | Step-by-step learning | âœ… Implemented | Good |

---

## ğŸ¯ **STRATEGIC DECISION: CHAIN vs TREE OF THOUGHT**

### **Option A: Chain of Thought (Current Approach)**
```
Research â†’ Generate â†’ Evaluate â†’ Compile â†’ Evaluate â†’ Output
```

**Pros:**
- âœ… Linear, predictable
- âœ… Easy to debug
- âœ… Fast (2-3 min)

**Cons:**
- âŒ No backtracking
- âŒ Can't recover from citation loss
- âŒ Each generation attempt is independent

---

### **Option B: Tree of Thought (Proposed)**
```
Research â†’ Generate (3 parallel branches)
              â†“
         Evaluate all 3
              â†“
         Select best OR combine
              â†“
         Compile with citation tracking
              â†“
         Evaluate â†’ If fail, recompile with feedback
```

**Pros:**
- âœ… Multiple attempts in parallel
- âœ… Can compare and select best
- âœ… Citation tracking across branches
- âœ… Better quality through competition

**Cons:**
- âŒ 3x API cost
- âŒ Slower (4-5 min)
- âŒ More complex to implement

---

### **Option C: Hybrid Approach (RECOMMENDED)**
```
Research â†’ Generate with explicit citation map
              â†“
         Evaluate (if < 75, regenerate with feedback)
              â†“
         Compile with citation preservation layer
              â†“
         Verify citations â†’ If lost, inject them back
              â†“
         Final evaluation
```

**Pros:**
- âœ… Citation preservation guaranteed
- âœ… Moderate cost (1.5x current)
- âœ… Faster than Tree of Thought
- âœ… Maintains linear flow

**Cons:**
- âš ï¸ Requires new "citation preservation layer"
- âš ï¸ More complex prompt engineering

---

## ğŸ› ï¸ **RECOMMENDED SOLUTION (Hybrid Approach)**

### **Phase 1: Fix Citation Preservation (CRITICAL - 1 hour)**

**1.1 Add Citation Tracking to Generation Prompt**
```python
# In SYSTEM_PROMPT, add explicit citation map section:
"""
CITATION MAP (DO NOT REMOVE):
After your answer, create a citation map:

CITATIONS USED:
- [doc-1]: <exact quote>
- [doc-2]: <exact quote>
...
"""
```

**1.2 Create Citation Preservation Layer**
```python
def preserve_citations(compiled: str, original: str) -> str:
    """Inject lost citations back into compiled content."""
    original_citations = extract_citations(original)
    compiled_citations = extract_citations(compiled)
    missing = original_citations - compiled_citations
    
    # For each missing citation, find best place to inject
    for citation in missing:
        # Use semantic similarity to find best paragraph
        best_para = find_best_paragraph(compiled, citation)
        compiled = inject_citation(compiled, best_para, citation)
    
    return compiled
```

**1.3 Update Compiler Prompt**
```python
COMPILER_PROMPT = """
CRITICAL: Preserve ALL citations exactly as they appear.

Before restructuring:
1. Extract all [doc-X] and [web-X] citations
2. Note which sentence each citation supports
3. After restructuring, ensure EVERY citation is still present
4. If a citation's sentence is split, attach citation to most relevant part

VERIFICATION:
- Count citations in input: {input_citation_count}
- Count citations in output: {output_citation_count}
- THEY MUST MATCH!
"""
```

---

### **Phase 2: Improve Generation Quality (HIGH - 1 hour)**

**2.1 Add Explicit Structure Template**
```python
GENERATION_TEMPLATE = """
Structure your answer as follows:

1. OPENING (2-3 sentences)
   - State the core concept
   - Why it matters
   - [citation]

2. FOUNDATION (3-4 paragraphs)
   - Define key terms with `backticks`
   - Provide 2-3 code examples
   - Cite sources [doc-X] or [web-X] after each claim

3. MECHANICS (2-3 paragraphs)
   - How it works step-by-step
   - Include numbered steps
   - Code examples with ```python blocks

4. PROGRESSIVE COMPLEXITY (2 paragraphs)
   - Simple example â†’ Complex example
   - Compare approaches

5. PRODUCTION PRACTICES (1-2 paragraphs)
   - Real-world usage
   - Best practices

TARGET: 40+ citations, 5+ code blocks, 20+ technical terms with `backticks`
"""
```

**2.2 Add Quality Checklist to Prompt**
```python
QUALITY_CHECKLIST = """
Before submitting, verify:
â–¡ 40+ citations ([doc-X] or [web-X])
â–¡ 5+ code blocks (```python)
â–¡ 20+ technical terms with `backticks`
â–¡ 2-4 citations per paragraph
â–¡ Every claim has a source
â–¡ Progressive examples (simple â†’ complex)
"""
```

---

### **Phase 3: Adjust Thresholds (QUICK - 15 min)**

**3.1 Lower Technical Preservation Floor**
```python
# In compiler_evaluator.py, line 100:
passed = total_score >= 95 and tech_score >= 20  # Was 28, now 20
```

**Rationale:**
- Current threshold (28/30) is too strict
- Allows 10-point deduction for citation loss
- Still maintains quality bar (95/100 total)

**3.2 Adjust Citation Density Threshold**
```python
# In rubric.py, line 85:
"citation_density": 2.0,  # Was 1.0, now 2.0 (more citations per 150 words)
```

---

## ğŸ“ˆ **EXPECTED IMPROVEMENTS**

### **After Phase 1 (Citation Preservation):**
| Metric | Current | Expected | Improvement |
|--------|---------|----------|-------------|
| Citation Preservation | 17-22% | 85-95% | +68% ğŸ¯ |
| Compiler Pass Rate | 50% | 90% | +40% |
| User Satisfaction | Low | High | âœ… |

### **After Phase 2 (Generation Quality):**
| Metric | Current | Expected | Improvement |
|--------|---------|----------|-------------|
| Generation Score | 65-68 | 80-85 | +17 points |
| Attempts to Pass | 6-7 | 2-3 | -60% time |
| Total Pipeline Time | 2-2.2 min | 1-1.5 min | -30% |

### **After Phase 3 (Threshold Adjustment):**
| Metric | Current | Expected | Improvement |
|--------|---------|----------|-------------|
| Compiler Pass Rate | 50% | 95% | +45% |
| False Negatives | High | Low | âœ… |

---

## ğŸ¯ **IMPLEMENTATION PRIORITY**

### **CRITICAL (Do First):**
1. âœ… **Phase 1.3**: Update Compiler Prompt (15 min)
2. âœ… **Phase 1.2**: Add Citation Preservation Layer (30 min)
3. âœ… **Phase 3.1**: Lower tech_preservation threshold (5 min)

### **HIGH (Do Next):**
4. âœ… **Phase 2.1**: Add Structure Template to Generation (30 min)
5. âœ… **Phase 2.2**: Add Quality Checklist (15 min)

### **MEDIUM (Do Later):**
6. âœ… **Phase 1.1**: Add Citation Tracking (30 min)
7. âœ… **Phase 3.2**: Adjust Citation Density (5 min)

---

## ğŸ¤” **RECOMMENDATION**

**Start with CRITICAL fixes (Phase 1.3, 1.2, 3.1) - Total: 50 minutes**

This will:
- âœ… Fix citation loss (biggest problem)
- âœ… Increase pass rate immediately
- âœ… Provide quick wins

Then assess results before moving to Phase 2.

---

## ğŸ“ **NEXT STEPS**

1. **User Decision**: Which phases to implement?
2. **Implementation**: Execute chosen phases
3. **Testing**: Run 5-10 test queries
4. **Measurement**: Compare before/after metrics
5. **Iteration**: Adjust based on results

---

**Ready to proceed?** ğŸš€

